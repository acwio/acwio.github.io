title: research
pubs:
 - name: "Seeing Sound: Investigating the Effects of Visualizations and Complexity on Crowdsourced Audio Annotations"
   description: Audio annotation is key to developing machine-listening systems; yet, effective ways to accurately and rapidly obtain crowdsourced audio annotations is understudied. In this work, we seek to quantify the relia- bility/redundancy trade-o  in crowdsourced soundscape annotation, investigate how visualizations a ect accuracy and e ciency, and characterize how performance varies as a function of audio characteristics. Using a controlled experiment, we varied sound visualizations and the complexity of soundscapes presented to human annotators. Results show that more complex audio scenes result in lower annotator agreement, and spectrogram visualizations are superior in producing higher quality annotations at lower cost of time and human labor. We also found recall is more a ected than precision by soundscape complexity, and mistakes can be often attributed to certain sound event characteristics. These  ndings have implications not only for how we should design annotation tasks and interfaces for audio data, but also how we train and evaluate machine-listening systems.
   citation: "Cartwright, M., Seals, A., Salamon, J., Williams, A.C., Mikloska, S., MacConnell, D., Law. E., Bello, J.P., and Nov, O. Seeing Sound: Investigating the Effects of Visualizations and Complexity on Crowdsourced Audio Annotations. Proceedings of the ACM Hum.-Comput. Interact. 1, 2, Article 29 (November 2017), 21 pages."
   soon: true
 - name: "Deja Vu: Characterizing Worker Reliability Using Task Consistency"
   description: Consistency is a practical metric that evaluates an instrument’s reliability based on its ability to yield the same output when repeatedly given a particular input. Despite its broad usage, little is understood about the feasibility of using con- sistency as a measure of worker reliability in crowdwork. In this paper, we explore the viability of measuring a worker’s reliability by their ability to conform to themselves. We in- troduce and describe Deja Vu, a mechanism for dynamically generating task queues with consistency probes to measure the consistency of workers who repeat the same task twice. We present a study that utilizes Deja Vu to examine how generic characteristics of the duplicate task — such as place- ment, difficulty, and transformation — affect a workers task consistency in the context of two unique object detection tasks. Our findings provide insight into the design and use of consistency-based reliability metrics.
   citation: "Williams, A.C., Goh, J., Willis, C.G., Ellison, A.M., Brusuelas, J.H., Davis, C.C., and Law. E.  (2017). Deja Vu: Characterizing Worker Reliability Using Task Consistency. Proceedings of the 5th AAAI Conference on Human Computation (HCOMP 2017)."
   pdf: /pubs/hcomp2017-dejavu.pdf
 - name: "Ensemble: A Hybrid Human-Machine System for Generating Melody Scores From Audio"
   description: Today, digital libraries, or digital repositories, can be found in nearly any discipline studying collections of text, manuscripts, or other variations of literature. However, many of these digital libraries operate on a traditional model that fails to lend itself to the user outside of fundamental operations (<i>i.e.</i>, Searching). Proteus, still a work-in-progress, leverages modern computing methods and techniques to aid the modern papyrologist in the study and analysis of papyrus fragments.
   citation: "Tse, T., Salamon, J., Williams, A.C., Jiang, H. and Law, E. (2016). Ensemble: A Hybrid Human-Machine System for Generating Melody Scores From Audio. Proceedings of the 17th International Society for Music Information Retrieval Conference (ISMIR 2016), New York City, USA, Aug. 2016."
   pdf: http://www.justinsalamon.com/uploads/4/3/9/4/4394963/tse_ensemble_ismir2016.pdf
 - name: "Crowdsourcing as a Tool for Research: Implications of Uncertainty"
   description: Numerous crowdsourcing platforms are now available to support research as well as commercial goals. However, crowdsourcing is not yet widely adopted by researchers for generating, processing or analyzing research data. This study develops a deeper understanding of the circumstances under which crowdsourcing is a useful, feasible or desirable tool for research, as well as the factors that may influence researchers’ decisions around adopting crowdsourcing technology. We conducted semi-structured interviews with 18 researchers in diverse disciplines, spanning the humanities and sciences, to illuminate how research norms and practitioners’ dispositions were related to uncertainties around research processes, data, knowledge, delegation and quality. The paper concludes with a discussion of the design implications for future crowdsourcing systems to support research.
   citation: "Law. E., Wiggins, A., Gajos, K., Gray, M.L., and Williams, A.C. Crowdsourcing as a Tool for Research: Implications of Uncertainty. Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing, CSCW '17, pages 1544-1561, New York, NY, USA, 2017."
   pdf: /pubs/cscw2017.pdf
 - name: "Proteus: A Platform for Born Digital Critical Editions of Literary and Subliterary Papyri"
   description: Today, digital libraries, or digital repositories, can be found in nearly any discipline studying collections of text, manuscripts, or other variations of literature. However, many of these digital libraries operate on a traditional model that fails to lend itself to the user outside of fundamental operations (<i>i.e.</i>, Searching). Proteus, still a work-in-progress, leverages modern computing methods and techniques to aid the modern papyrologist in the study and analysis of papyrus fragments.
   citation: "Williams, A.C., Santarsiero, A., Meccariello, C., Verhasselt, G., Wallin, J.F., Carroll, H.D., & Brusuelas, J.H. (2015). Proteus: A Platform for Born Digital Critical Editions of Literary and Subliterary Papyri. Proceedings of the Digital Heritage 2015."
   pdf: /pubs/dh2015.pdf
 - name: Computationally Accelerated Papyrology
   description: This thesis presents two computational approaches for accelerating papyrus transcription and identification. The first approach is a computational pipeline that aggregates millions of crowdsourced letter classifications into transcriptions of papyrus fragments. The second approach leverages genetic sequence alignment algorithms to rapidly identify damaged papyrus fragments to known papyrus manuscripts. These approaches greatly improve upon the current state-of-the-art techniques and set a new standard for leveraging computation to the transcription and identification of ancient texts.
   citation: Williams, A.C. (2015). Computationally Accelerated Papyrology.
   pdf: /pubs/thesis2015.pdf
   thesis: 'true'
 - name: "A Computational Pipeline for Crowdsourced Transcriptions of Ancient Greek Papyrus Fragments"
   description: To date, over 7 million letter identifications from users across the world have been recorded in the Ancient Lives database. In this paper, we present a computational pipeline for converting crowdsourced letter identifications made through the Ancient Lives interface into digital consensus transcriptions of papyrus fragments. We conclude by explaining the usefulness of the pipeline output in the context of additional computational projects that aim to further accelerate the identification process.
   citation: Williams, A.C., Wallin, J.F., Yu. H, Carroll, H.D., Lamblin., A-F., Fortson, L., Obbink, D., Lintott, C.J. & Brusuelas, J.H. (2014). A Computational Pipeline For Crowdsourced Transcriptions of Ancient Greek Papyrus Fragments. Proceedings of the 2014 IEEE Conference on Big Data (Big Data). Washington D.C., USA.
   pdf: /pubs/bhd2014.pdf
 - name: Improving Retrieval Efficacy of Homology Searches using the False Discovery Rate
   description: In genetic sequence alignment, comparative accuracy of retrieval algorithms (e.g., BLAST) has been rigorously studied for improvement. Unlike most components of retrieval algorithms, the E-value threshold criterion has yet to be thoroughly investigated. An investigation of the threshold is important as it exclusively dictates which sequences are declared relevant and irrelevant. In this paper, we introduce the false discovery rate (FDR) statistic as a replacement for the uniform threshold criterion in order to improve efficacy in retrieval systems
   citation: Carroll, H.D., Williams, A.C., Davis, A.G., & Spouge, J.L. (2014). Improving Retrieval Efficacy Using the False Discovery Rate. Transactions on Computational Biology and Bioinformatics. Transactions on Computational Biology and Bioinformatics (TCBB), 2014.
   pdf: /pubs/tcbb2014.pdf
 - name: Identification of Ancient Greek Papyrus Fragments Using Genetic Sequence Alignment Algorithms
   description: A key task performed by papyrologists is determining if an unknown fragment belongs to a literary manuscript. In this paper, we introduce a novel methodology that uses modern genetic sequence alignment algorithms as a method for identifying Ancient Greek text fragments. This application will offer papyrologists and other professionals in the humanities the ability to rapidly identify severely damaged texts. This approach leverages a new form of non-contextual, multi-line text identification for the Greek language that can greatly accelerate the tedious task of transcription and identification
   citation: Williams, A.C., Carroll, H.D., Wallin, J.F., Brusuelas, J., Fortson, L., Lamblin., A-F., & Yu, H. (2014). Identification of Ancient Greek Papyrus Fragments Using Genetic Sequence Alignment Algorithms. Proceedings of the 2014 IEEE Conference on e-Science (e-Science). Guarujá, Brazil.
   pdf: /pubs/escience2014.pdf
 - name: False Discovery Rate for Homology Searches
   description: While many different aspects of retrieval algorithms (e.g., BLAST) have been studied in depth, the method for determining the retrieval threshold has not enjoyed the same attention. Furthermore, with genetic databases growing rapidly, the challenges of multiple testing are escalating. In order to improve search sensitivity, we propose the use of the false discovery rate (FDR) as the method to control the number of irrelevant (“false positive”) sequences. In this paper, we introduce BLAST-FDR, an extended version of BLAST that uses a FDR method for the threshold criterion.
   citation: Carroll, H D., Williams, A.C., Davis, A.G., & Spouge, J.L. (2013). False Discovery Rate for Homology Searches. Advances in Bioinformatics and Computational Biology, 194-201.
   pdf: /pubs/bsb2013.pdf
 - name: Automated assessment of bilateral breast volume asymmetry as a breast cancer biomarker during mammographic screening.
   description: The biological concept of bilateral symmetry as a marker of developmental stability and good health is well established. The study suggests that automated assessment of global bilateral asymmetry could serve as a breast cancer risk biomarker for women undergoing mammographic screening. Such biomarker could be used to alert radiologists or computer-assisted detection (CAD) systems to exercise increased vigilance if higher than normal cancer risk is suspected.
   citation: Williams, A.C., Hitt, A., Voisin, S., & Tourassi, G. (2013, March). Automated assessment of bilateral breast volume asymmetry as a breast cancer biomarker during mammographic screening. In SPIE Medical Imaging (pp. 86701A-86701A). International Society for Optics and Photonics.
   pdf: /pubs/spie2013.pdf